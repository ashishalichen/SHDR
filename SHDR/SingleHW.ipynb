{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# scipy.special for the sigmoid function expit()\n",
    "import scipy.special\n",
    "# library for plotting arrays\n",
    "import matplotlib.pyplot\n",
    "# ensure the plots are inside this notebook, not an external window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper to load data from PNG image files\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"mnist_train_100.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 10\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift the inputs\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test with our own image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ... \n",
      "min =  0.01\n",
      "max =  0.9417647\n",
      "[[0.04026343]\n",
      " [0.0390093 ]\n",
      " [0.03270639]\n",
      " [0.02053594]\n",
      " [0.03039591]\n",
      " [0.03760604]\n",
      " [0.07878174]\n",
      " [0.03001848]\n",
      " [0.8691823 ]\n",
      " [0.03160447]]\n",
      "network says  8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the neural network with our own images\n",
    "\n",
    "# load image data from png files into an array\n",
    "print (\"loading ... \")\n",
    "img_array = imageio.imread('images/08.png', as_gray=True)\n",
    "    \n",
    "# reshape from 28x28 to list of 784 values, invert values\n",
    "img_data  = 255.0 - img_array.reshape(784)\n",
    "    \n",
    "# then scale data to range from 0.01 to 1.0\n",
    "img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "print(\"min = \", numpy.min(img_data))\n",
    "print(\"max = \", numpy.max(img_data))\n",
    "\n",
    "# plot image\n",
    "matplotlib.pyplot.imshow(img_data.reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "# query the network\n",
    "outputs = n.query(img_data)\n",
    "print (outputs)\n",
    "\n",
    "# the index of the highest value corresponds to the label\n",
    "label = numpy.argmax(outputs)\n",
    "print(\"network says \", label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
